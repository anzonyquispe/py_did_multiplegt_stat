{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the pairwise notebook (so this notebook is standalone)\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "\n",
    "def _exec_notebook(path: Path) -> None:\n",
    "    \"\"\"Execute all *code* cells of a notebook into the current IPython kernel.\"\"\"\n",
    "    nb = nbformat.read(path, as_version=4)\n",
    "    ip = get_ipython()\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source.strip():\n",
    "            ip.run_cell(cell.source)\n",
    "\n",
    "\n",
    "def _find_local_notebook(name: str) -> Path:\n",
    "    \"\"\"Find a notebook file by searching common locations.\"\"\"\n",
    "    candidates = []\n",
    "    # 1) current working directory and a few parents\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(3):\n",
    "        candidates.append(p / name)\n",
    "        p = p.parent\n",
    "    # 2) fallback: /mnt/data (common in sandboxes)\n",
    "    candidates.append(Path('/mnt/data') / name)\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(f\"Cannot find {name}. Looked in: \" + \", \".join(str(c) for c in candidates))\n",
    "\n",
    "pairwise_nb = _find_local_notebook('did_multiplegt_stat_pairwise.ipynb')\n",
    "if 'did_multiplegt_stat_pairwise' not in globals():\n",
    "    if not pairwise_nb.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"Cannot find 'did_multiplegt_stat_pairwise.ipynb' in the current folder. \"\n",
    "            \"Put it next to this notebook, then Run All again.\"\n",
    "        )\n",
    "    _exec_notebook(pairwise_nb)\n",
    "    print('Loaded pairwise from', pairwise_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8dbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _balance_panel_fill(df: pd.DataFrame, id_col: str, t_col: str) -> pd.DataFrame:\n",
    "    # Replicates make.pbalanced(..., balance.type=\"fill\") (plm/R)\n",
    "    # - adds missing rows ID x T con NA\n",
    "    # - creates tsfilled_XX = 1 si fue \u201crellenado\u201d\n",
    "    # - re-maps T a 1..T en orden creciente de los valores originales\n",
    "    df = df.copy()\n",
    "    df[\"tsfilled_XX\"] = 0\n",
    "\n",
    "    times = pd.Series(df[t_col].dropna().unique()).sort_values().to_list()\n",
    "    ids = pd.Series(df[id_col].dropna().unique()).to_list()\n",
    "\n",
    "    mi = pd.MultiIndex.from_product([ids, times], names=[id_col, t_col])\n",
    "\n",
    "    df_bal = (\n",
    "        df.set_index([id_col, t_col])\n",
    "          .reindex(mi)\n",
    "          .reset_index()\n",
    "    )\n",
    "    df_bal[\"tsfilled_XX\"] = df_bal[\"tsfilled_XX\"].isna().astype(int)\n",
    "\n",
    "    time_map = {t: i + 1 for i, t in enumerate(times)}\n",
    "    df_bal[t_col] = df_bal[t_col].map(time_map).astype(int)\n",
    "\n",
    "    return df_bal\n",
    "\n",
    "\n",
    "def _se_from_phi(phi: pd.Series) -> float:\n",
    "    # SE = sd(phi)/sqrt(n), ignorando NA.\n",
    "    phi = pd.to_numeric(phi, errors=\"coerce\").dropna()\n",
    "    n = len(phi)\n",
    "    if n <= 1:\n",
    "        return np.nan\n",
    "    return float(phi.std(ddof=1) / math.sqrt(n))\n",
    "\n",
    "\n",
    "def _se_cluster_from_phi(ids_df: pd.DataFrame, cluster_col: str, phi_col: str, N_bar_c: float) -> float:\n",
    "    # Cluster-robusta al estilo del main en R:\n",
    "    #   SE = sd( sum_c Phi_c ) / sqrt(#clusters) / sqrt(N_bar_c)\n",
    "    # donde Phi_c = suma de Phi por cluster, y N_bar_c = tama\u00f1o promedio del cluster (#IDs).\n",
    "    tmp = ids_df[[cluster_col, phi_col]].copy()\n",
    "    tmp[phi_col] = pd.to_numeric(tmp[phi_col], errors=\"coerce\")\n",
    "\n",
    "    s = tmp.groupby(cluster_col)[phi_col].sum(min_count=1).dropna()\n",
    "    if len(s) <= 1:\n",
    "        return np.nan\n",
    "    if (not np.isfinite(N_bar_c)) or (N_bar_c <= 0):\n",
    "        return np.nan\n",
    "\n",
    "    return float(s.std(ddof=1) / math.sqrt(len(s)) / math.sqrt(float(N_bar_c)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the main aggregation function that mirrors the R `did_multiplegt_stat_main` logic.\n",
    "def did_multiplegt_stat_main(\n",
    "    # Parameter `df`: The input long-format panel DataFrame.\n",
    "    df: pd.DataFrame,\n",
    "    # Parameter `Y`: Name of the outcome column in `df`.\n",
    "    Y: str,\n",
    "    # Parameter `ID`: Name of the unit identifier column in `df`.\n",
    "    ID: str,\n",
    "    # Parameter `Time`: Name of the time-period column in `df`.\n",
    "    Time: str,\n",
    "    # Parameter `D`: Name of the treatment column in `df`.\n",
    "    D: str,\n",
    "    # Parameter `Z`: Optional instrument column name (only used for ivwaoss).\n",
    "    Z: Optional[str],\n",
    "    # Parameter `estimator`: List of estimators to compute: any of {'aoss','waoss','ivwaoss'}.\n",
    "    estimator: List[str],\n",
    "    # Parameter `estimation_method`: Estimation method passed to pairwise (e.g., 'dr', 'ra', 'ps').\n",
    "    estimation_method: str,\n",
    "    # Parameter `order`: Order for the local polynomial / regression components (passed to pairwise).\n",
    "    order: int,\n",
    "    # Parameter `noextrapolation`: If True, enforce support restrictions (passed to pairwise).\n",
    "    noextrapolation: bool,\n",
    "    # Parameter `placebo`: If True, also compute placebo estimates (pre-trends style).\n",
    "    placebo: bool,\n",
    "    # Parameter `switchers`: Which switchers to use (e.g., 'up', 'down', or None for both).\n",
    "    switchers: Optional[str],\n",
    "    # Parameter `disaggregate`: Whether to keep disaggregated outputs (kept for API parity).\n",
    "    disaggregate: bool,\n",
    "    # Parameter `aoss_vs_waoss`: If True, compute an AOSS vs WAOSS difference test.\n",
    "    aoss_vs_waoss: bool,\n",
    "    # Parameter `exact_match`: If True, enforce exact matching support restrictions (passed to pairwise).\n",
    "    exact_match: bool,\n",
    "    # Parameter `weight`: Optional weight column name; if None, uses 1.\n",
    "    weight: Optional[str],\n",
    "    # Parameter `cluster`: Optional clustering column name (must be coarser than ID).\n",
    "    cluster: Optional[str],\n",
    "    # Parameter `by_fd_opt`: Optional settings for by-first-difference logic (passed to pairwise).\n",
    "    by_fd_opt: Optional[Any],\n",
    "    # Parameter `other_treatments`: Optional list of additional treatment columns to control for (passed to pairwise).\n",
    "    other_treatments: Optional[List[str]],\n",
    "    # Parameter `legacy_r_phi_scale`: Controls the legacy rescaling of influence functions to match the R SE output.\n",
    "    legacy_r_phi_scale: str = \"off\",  # \"auto\" | \"on\" | \"off\"\n",
    "# Close the signature and declare the return type.\n",
    ") -> Dict[str, Any]:\n",
    "    # Main Python (high-fidelity) inspired by did_multiplegt_stat_main (R).\n",
    "    # Compatibility:\n",
    "    # - legacy_r_phi_scale=\"on\" intenta detectar si pairwise devuelve SE m\u00e1s chico que sd/sqrt(n) y reescala Phi.\n",
    "    # Flag whether AOSS is requested (1) or not (0).\n",
    "    aoss_XX = int(\"aoss\" in estimator)\n",
    "    # Flag whether WAOSS is requested (1) or not (0).\n",
    "    waoss_XX = int(\"waoss\" in estimator)\n",
    "    # Flag whether IVWAOSS is requested (1) or not (0).\n",
    "    ivwaoss_XX = int(\"ivwaoss\" in estimator)\n",
    "\n",
    "    # select the required columns\n",
    "    # Execute this statement as part of the main procedure.\n",
    "    varlist: List[str] = []\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for v in [Y, ID, Time, D, Z, weight, cluster] + (other_treatments or []):\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if v is not None and v not in varlist:\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            varlist.append(v)\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if \"partition_XX\" in df.columns and \"partition_XX\" not in varlist:\n",
    "        # Execute this call (a helper/utility step needed for the main procedure).\n",
    "        varlist.append(\"partition_XX\")\n",
    "    # Compute and store `df`.\n",
    "    df = df[varlist].copy()\n",
    "\n",
    "    # map to *_XX\n",
    "    # Build a mapping from internal standardized names (*_XX) to user-provided column names.\n",
    "    mapping = {\"Y_XX\": Y, \"ID_XX\": ID, \"T_XX\": Time, \"D_XX\": D}\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if Z is not None:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        mapping[\"Z_XX\"] = Z\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if weight is not None:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        mapping[\"weight_XX\"] = weight\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if cluster is not None:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        mapping[\"cluster_XX\"] = cluster\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for new_col, old_col in mapping.items():\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if old_col is not None:\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            df[new_col] = df[old_col]\n",
    "\n",
    "    # check cluster nestedness (si cluster==ID, ignorar)\n",
    "    # Compute and store `n_clus_XX`.\n",
    "    n_clus_XX = None\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if cluster is not None:\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if cluster == ID:\n",
    "            # Compute and store `cluster`.\n",
    "            cluster = None\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            df.drop(columns=[\"cluster_XX\"], inplace=True, errors=\"ignore\")\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            print(\"\ufe0f cluster == ID. Ignoro cluster (como en R).\")\n",
    "        # Fallback branch executed when none of the previous conditions matched.\n",
    "        else:\n",
    "            # Compute and store `g`.\n",
    "            g = df.groupby(\"ID_XX\")[\"cluster_XX\"].nunique(dropna=True)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if (g > 1).any():\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                raise ValueError(\"La variable ID debe estar anidada dentro de cluster (cluster constante por ID).\")\n",
    "            # Compute and store `n_clus_XX`.\n",
    "            n_clus_XX = int(df[\"cluster_XX\"].nunique(dropna=True))\n",
    "\n",
    "    # drop NAs en ID/T/D (y Z si IV)\n",
    "    # Execute this call (a helper/utility step needed for the main procedure).\n",
    "    df[\"to_drop_XX\"] = df[\"T_XX\"].isna() | df[\"D_XX\"].isna() | df[\"ID_XX\"].isna()\n",
    "    # Compute and store `IV_req_XX`.\n",
    "    IV_req_XX = 0\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if ivwaoss_XX == 1:\n",
    "        # Compute and store `IV_req_XX`.\n",
    "        IV_req_XX = 1\n",
    "        # Execute this call (a helper/utility step needed for the main procedure).\n",
    "        df[\"to_drop_XX\"] = df[\"to_drop_XX\"] | df[\"Z_XX\"].isna()\n",
    "    # Compute and store `df`.\n",
    "    df = df.loc[~df[\"to_drop_XX\"]].copy()\n",
    "\n",
    "    # balancear panel y remapear T\n",
    "    # Compute and store `df`.\n",
    "    df = _balance_panel_fill(df, id_col=\"ID_XX\", t_col=\"T_XX\")\n",
    "\n",
    "    # pesos\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if weight is None:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        df[\"weight_XX\"] = 1.0\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        df[\"weight_c_XX\"] = 1.0\n",
    "    # Fallback branch executed when none of the previous conditions matched.\n",
    "    else:\n",
    "        # Execute this call (a helper/utility step needed for the main procedure).\n",
    "        df[\"weight_XX\"] = df[\"weight_XX\"].fillna(0.0).astype(float)\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        df[\"weight_c_XX\"] = 1.0\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if cluster is not None:\n",
    "        # Execute this call (a helper/utility step needed for the main procedure).\n",
    "        df[\"weight_c_XX\"] = df.groupby([\"cluster_XX\", \"T_XX\"])[\"weight_XX\"].transform(\"sum\").astype(float)\n",
    "\n",
    "    # IDs dataframe\n",
    "    # Create the per-unit table that will store influence-function components.\n",
    "    IDs_XX = pd.DataFrame({\"ID_XX\": pd.Series(df[\"ID_XX\"].unique()).sort_values().to_numpy()})\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if cluster is not None:\n",
    "        # Create the per-unit table that will store influence-function components.\n",
    "        IDs_XX = IDs_XX.merge(df.groupby(\"ID_XX\")[\"cluster_XX\"].mean().reset_index(), on=\"ID_XX\", how=\"left\")\n",
    "\n",
    "    # Compute the maximum (re-mapped) time index in the balanced panel.\n",
    "    max_T_XX = int(df[\"T_XX\"].max())\n",
    "\n",
    "    # scalars\n",
    "    # Execute this statement as part of the main procedure.\n",
    "    scalars: Dict[str, Any] = dict(\n",
    "        # Compute and store `PS_sum_XX`.\n",
    "        PS_sum_XX=0.0, delta_1_1_XX=0.0,\n",
    "        # Compute and store `E_abs_delta_D_sum_XX`.\n",
    "        E_abs_delta_D_sum_XX=0.0, delta_2_1_XX=0.0,\n",
    "        # Compute and store `denom_delta_IV_sum_XX`.\n",
    "        denom_delta_IV_sum_XX=0.0, delta_3_1_XX=0.0,\n",
    "        # Compute and store `N_Switchers_1_1_XX`.\n",
    "        N_Switchers_1_1_XX=0.0, N_Stayers_1_1_XX=0.0,\n",
    "        # Compute and store `N_Switchers_2_1_XX`.\n",
    "        N_Switchers_2_1_XX=0.0, N_Stayers_2_1_XX=0.0,\n",
    "        # Compute and store `N_Switchers_3_1_XX`.\n",
    "        N_Switchers_3_1_XX=0.0, N_Stayers_3_1_XX=0.0,\n",
    "        # Compute and store `N_drop_total_XX`.\n",
    "        N_drop_total_XX=0.0, N_drop_total_C_XX=0.0,\n",
    "        # Compute and store `IV_req_XX`.\n",
    "        IV_req_XX=float(IV_req_XX),\n",
    "    # Execute this statement as part of the main procedure.\n",
    "    )\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if bool(placebo):\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars.update(dict(\n",
    "            # Compute and store `PS_sum_pl_XX`.\n",
    "            PS_sum_pl_XX=0.0, delta_1_1_pl_XX=0.0,\n",
    "            # Compute and store `E_abs_delta_D_sum_pl_XX`.\n",
    "            E_abs_delta_D_sum_pl_XX=0.0, delta_2_1_pl_XX=0.0,\n",
    "            # Compute and store `denom_delta_IV_sum_pl_XX`.\n",
    "            denom_delta_IV_sum_pl_XX=0.0, delta_3_1_pl_XX=0.0,\n",
    "            # Compute and store `N_Switchers_1_1_pl_XX`.\n",
    "            N_Switchers_1_1_pl_XX=0.0, N_Stayers_1_1_pl_XX=0.0,\n",
    "            # Compute and store `N_Switchers_2_1_pl_XX`.\n",
    "            N_Switchers_2_1_pl_XX=0.0, N_Stayers_2_1_pl_XX=0.0,\n",
    "            # Compute and store `N_Switchers_3_1_pl_XX`.\n",
    "            N_Switchers_3_1_pl_XX=0.0, N_Stayers_3_1_pl_XX=0.0,\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        ))\n",
    "\n",
    "    # auto legacy scaling: ajustar Phi_* para igualar el SE que pairwise reporta\n",
    "    # Execute this statement as part of the main procedure.\n",
    "    def _maybe_rescale_phi_auto(to_add: pd.DataFrame, scalars_out: Dict[str, Any], p: int, pl_suffix: str) -> pd.DataFrame:\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if legacy_r_phi_scale == \"off\":\n",
    "            # Return the final output dictionary to the caller.\n",
    "            return to_add\n",
    "\n",
    "        # Start a loop that iterates over the specified sequence.\n",
    "        for j, enabled in [(2, waoss_XX), (1, aoss_XX), (3, ivwaoss_XX)]:\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if enabled != 1:\n",
    "                # Execute this statement as part of the main procedure.\n",
    "                continue\n",
    "            # Compute and store `phi_col`.\n",
    "            phi_col = f\"Phi_{j}_{p}{pl_suffix}_XX\"\n",
    "            # Compute and store `se_key`.\n",
    "            se_key  = f\"sd_delta_{j}_{p}{pl_suffix}_XX\"\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if phi_col in to_add.columns and se_key in scalars_out:\n",
    "                # Compute and store `se_target`.\n",
    "                se_target = float(scalars_out.get(se_key, np.nan))\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if not np.isfinite(se_target) or se_target <= 0:\n",
    "                    # Execute this statement as part of the main procedure.\n",
    "                    continue\n",
    "                # Compute and store `se_direct`.\n",
    "                se_direct = _se_from_phi(to_add[phi_col])\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if not np.isfinite(se_direct) or se_direct <= 0:\n",
    "                    # Execute this statement as part of the main procedure.\n",
    "                    continue\n",
    "\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if legacy_r_phi_scale == \"on\":\n",
    "                    # Compute and store `W_key`.\n",
    "                    W_key = f\"W{pl_suffix}_XX\" if f\"W{pl_suffix}_XX\" in scalars_out else \"W_XX\"\n",
    "                    # Compute and store `W`.\n",
    "                    W = float(scalars_out.get(W_key, np.nan))\n",
    "                    # Compute and store `scale`.\n",
    "                    scale = (1.0 / math.sqrt(W)) if (np.isfinite(W) and W > 0) else (se_target / se_direct)\n",
    "                # Fallback branch executed when none of the previous conditions matched.\n",
    "                else:\n",
    "                    # Compute and store `ratio`.\n",
    "                    ratio = se_target / se_direct\n",
    "                    # Conditional branch: execute the following block only if the condition is true.\n",
    "                    if abs(ratio - 1.0) < 0.10:\n",
    "                        # Return the final output dictionary to the caller.\n",
    "                        return to_add\n",
    "                    # Compute and store `scale`.\n",
    "                    scale = ratio\n",
    "\n",
    "                # Start a loop that iterates over the specified sequence.\n",
    "                for jj in (1, 2, 3):\n",
    "                    # Compute and store `c`.\n",
    "                    c = f\"Phi_{jj}_{p}{pl_suffix}_XX\"\n",
    "                    # Conditional branch: execute the following block only if the condition is true.\n",
    "                    if c in to_add.columns:\n",
    "                        # Execute this statement as part of the main procedure.\n",
    "                        to_add[c] = pd.to_numeric(to_add[c], errors=\"coerce\") * scale\n",
    "                # Return the final output dictionary to the caller.\n",
    "                return to_add\n",
    "        # Return the final output dictionary to the caller.\n",
    "        return to_add\n",
    "\n",
    "    # LOOP principal\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for p in range(2, max_T_XX + 1):\n",
    "        # Compute and store `est_out`.\n",
    "        est_out = did_multiplegt_stat_pairwise(\n",
    "            # Compute and store `df`.\n",
    "            df=df,\n",
    "            # Compute and store `Y`.\n",
    "            Y=\"Y_XX\", ID=\"ID_XX\", Time=\"T_XX\", D=\"D_XX\",\n",
    "            # Compute and store `Z`.\n",
    "            Z=(\"Z_XX\" if Z is not None else None),\n",
    "            # Compute and store `estimator`.\n",
    "            estimator=estimator,\n",
    "            # Compute and store `order`.\n",
    "            order=order,\n",
    "            # Compute and store `noextrapolation`.\n",
    "            noextrapolation=noextrapolation,\n",
    "            # Compute and store `weight`.\n",
    "            weight=\"weight_XX\",\n",
    "            # Compute and store `switchers`.\n",
    "            switchers=switchers,\n",
    "            # Compute and store `pairwise`.\n",
    "            pairwise=p,\n",
    "            # Compute and store `IDs`.\n",
    "            IDs=IDs_XX,\n",
    "            # Compute and store `aoss`.\n",
    "            aoss=aoss_XX, waoss=waoss_XX, ivwaoss=ivwaoss_XX,\n",
    "            # Compute and store `estimation_method`.\n",
    "            estimation_method=estimation_method,\n",
    "            # Initialize the dictionary of scalar accumulators used across pairwise computations.\n",
    "            scalars=scalars,\n",
    "            # Compute and store `placebo`.\n",
    "            placebo=0,  # FIXED: use 0 instead of False\n",
    "            # Compute and store `exact_match`.\n",
    "            exact_match=exact_match,\n",
    "            # Compute and store `cluster`.\n",
    "            cluster=cluster,\n",
    "            # Compute and store `by_fd_opt`.\n",
    "            by_fd_opt=by_fd_opt,\n",
    "            # Compute and store `other_treatments`.\n",
    "            other_treatments=other_treatments,\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        )\n",
    "        # Compute and store `to_add`.\n",
    "        to_add = est_out.get(\"to_add\", None)\n",
    "        # Initialize the dictionary of scalar accumulators used across pairwise computations.\n",
    "        scalars = est_out[\"scalars\"]\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if to_add is not None and isinstance(to_add, pd.DataFrame) and len(to_add) > 0:\n",
    "            # Compute and store `to_add`.\n",
    "            to_add = _maybe_rescale_phi_auto(to_add, scalars, p=p, pl_suffix=\"\")\n",
    "            # Create the per-unit table that will store influence-function components.\n",
    "            IDs_XX = IDs_XX.merge(to_add, on=\"ID_XX\", how=\"left\").sort_values(\"ID_XX\").reset_index(drop=True)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if aoss_XX == 1:\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            scalars[\"delta_1_1_XX\"] += scalars.get(f\"P_{p}_XX\", 0.0) * scalars.get(f\"delta_1_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Stayers_1_{p}_XX\", 0.0) > 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Switchers_1_1_XX\"] += scalars.get(f\"N_Switchers_1_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Switchers_1_{p}_XX\", 0.0) > 0:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Stayers_1_1_XX\"] += scalars.get(f\"N_Stayers_1_{p}_XX\", 0.0)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if waoss_XX == 1:\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            scalars[\"delta_2_1_XX\"] += scalars.get(f\"E_abs_delta_D_{p}_XX\", 0.0) * scalars.get(f\"delta_2_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Stayers_2_{p}_XX\", 0.0) > 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Switchers_2_1_XX\"] += scalars.get(f\"N_Switchers_2_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Switchers_2_{p}_XX\", 0.0) > 0:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Stayers_2_1_XX\"] += scalars.get(f\"N_Stayers_2_{p}_XX\", 0.0)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if ivwaoss_XX == 1:\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            scalars[\"delta_3_1_XX\"] += scalars.get(f\"denom_delta_IV_{p}_XX\", 0.0) * scalars.get(f\"delta_3_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Stayers_3_{p}_XX\", 0.0) > 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Switchers_3_1_XX\"] += scalars.get(f\"N_Switchers_3_{p}_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if scalars.get(f\"N_Switchers_3_{p}_XX\", 0.0) > 0:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"N_Stayers_3_1_XX\"] += scalars.get(f\"N_Stayers_3_{p}_XX\", 0.0)\n",
    "\n",
    "    # LOOP placebo\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if bool(placebo):\n",
    "        # FIXED: placebo_index = 1 (for now only support single placebo)\n",
    "        # In Stata: forvalues placebo_index = 1/`placebo'\n",
    "        placebo_index = 1\n",
    "        \n",
    "        # FIXED: Loop starts at p = 2 + placebo_index (for placebo_index=1, starts at 3)\n",
    "        # In Stata: forvalues p = `=2+`placebo_index''/`=max_T'\n",
    "        for p in range(2 + placebo_index, max_T_XX + 1):\n",
    "            # Compute and store `est_out`.\n",
    "            est_out = did_multiplegt_stat_pairwise(\n",
    "                # Compute and store `df`.\n",
    "                df=df,\n",
    "                # Compute and store `Y`.\n",
    "                Y=\"Y_XX\", ID=\"ID_XX\", Time=\"T_XX\", D=\"D_XX\",\n",
    "                # Compute and store `Z`.\n",
    "                Z=(\"Z_XX\" if Z is not None else None),\n",
    "                # Compute and store `estimator`.\n",
    "                estimator=estimator,\n",
    "                # Compute and store `order`.\n",
    "                order=order,\n",
    "                # Compute and store `noextrapolation`.\n",
    "                noextrapolation=noextrapolation,\n",
    "                # Compute and store `weight`.\n",
    "                weight=\"weight_XX\",\n",
    "                # Compute and store `switchers`.\n",
    "                switchers=switchers,\n",
    "                # Compute and store `pairwise`.\n",
    "                pairwise=p,\n",
    "                # Compute and store `IDs`.\n",
    "                IDs=IDs_XX,\n",
    "                # Compute and store `aoss`.\n",
    "                aoss=aoss_XX, waoss=waoss_XX, ivwaoss=ivwaoss_XX,\n",
    "                # Compute and store `estimation_method`.\n",
    "                estimation_method=estimation_method,\n",
    "                # Initialize the dictionary of scalar accumulators used across pairwise computations.\n",
    "                scalars=scalars,\n",
    "                # FIXED: pass placebo index (int) instead of True\n",
    "                placebo=placebo_index,\n",
    "                # Compute and store `exact_match`.\n",
    "                exact_match=exact_match,\n",
    "                # Compute and store `cluster`.\n",
    "                cluster=cluster,\n",
    "                # Compute and store `by_fd_opt`.\n",
    "                by_fd_opt=by_fd_opt,\n",
    "                # Compute and store `other_treatments`.\n",
    "                other_treatments=other_treatments,\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            )\n",
    "            # Compute and store `to_add`.\n",
    "            to_add = est_out.get(\"to_add\", None)\n",
    "            # Initialize the dictionary of scalar accumulators used across pairwise computations.\n",
    "            scalars = est_out[\"scalars\"]\n",
    "\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if to_add is not None and isinstance(to_add, pd.DataFrame) and len(to_add) > 0:\n",
    "                # Compute and store `to_add`.\n",
    "                to_add = _maybe_rescale_phi_auto(to_add, scalars, p=p, pl_suffix=\"_pl\")\n",
    "                # Create the per-unit table that will store influence-function components.\n",
    "                IDs_XX = IDs_XX.merge(to_add, on=\"ID_XX\", how=\"left\").sort_values(\"ID_XX\").reset_index(drop=True)\n",
    "\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if aoss_XX == 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"delta_1_1_pl_XX\"] += scalars.get(f\"P_{p}_pl_XX\", 0.0) * scalars.get(f\"delta_1_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Stayers_1_{p}_pl_XX\", 0.0) > 1:\n",
    "                    scalars[\"N_Switchers_1_1_pl_XX\"] += scalars.get(f\"N_Switchers_1_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Switchers_1_{p}_pl_XX\", 0.0) > 0:\n",
    "                    scalars[\"N_Stayers_1_1_pl_XX\"] += scalars.get(f\"N_Stayers_1_{p}_pl_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if waoss_XX == 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"delta_2_1_pl_XX\"] += scalars.get(f\"E_abs_delta_D_{p}_pl_XX\", 0.0) * scalars.get(f\"delta_2_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Stayers_2_{p}_pl_XX\", 0.0) > 1:\n",
    "                    scalars[\"N_Switchers_2_1_pl_XX\"] += scalars.get(f\"N_Switchers_2_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Switchers_2_{p}_pl_XX\", 0.0) > 0:\n",
    "                    scalars[\"N_Stayers_2_1_pl_XX\"] += scalars.get(f\"N_Stayers_2_{p}_pl_XX\", 0.0)\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if ivwaoss_XX == 1:\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                scalars[\"delta_3_1_pl_XX\"] += scalars.get(f\"denom_delta_IV_{p}_pl_XX\", 0.0) * scalars.get(f\"delta_3_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Stayers_3_{p}_pl_XX\", 0.0) > 1:\n",
    "                    scalars[\"N_Switchers_3_1_pl_XX\"] += scalars.get(f\"N_Switchers_3_{p}_pl_XX\", 0.0)\n",
    "                if scalars.get(f\"N_Switchers_3_{p}_pl_XX\", 0.0) > 0:\n",
    "                    scalars[\"N_Stayers_3_1_pl_XX\"] += scalars.get(f\"N_Stayers_3_{p}_pl_XX\", 0.0)\n",
    "\n",
    "    # dividir por sumas\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if aoss_XX == 1 and scalars.get(\"PS_sum_XX\", 0.0) != 0:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[\"delta_1_1_XX\"] /= scalars[\"PS_sum_XX\"]\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if bool(placebo) and scalars.get(\"PS_sum_pl_XX\", 0.0) != 0:\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[\"delta_1_1_pl_XX\"] /= scalars[\"PS_sum_pl_XX\"]\n",
    "\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if waoss_XX == 1 and scalars.get(\"E_abs_delta_D_sum_XX\", 0.0) != 0:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[\"delta_2_1_XX\"] /= scalars[\"E_abs_delta_D_sum_XX\"]\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if bool(placebo) and scalars.get(\"E_abs_delta_D_sum_pl_XX\", 0.0) != 0:\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[\"delta_2_1_pl_XX\"] /= scalars[\"E_abs_delta_D_sum_pl_XX\"]\n",
    "\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if ivwaoss_XX == 1 and scalars.get(\"denom_delta_IV_sum_XX\", 0.0) != 0:\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[\"delta_3_1_XX\"] /= scalars[\"denom_delta_IV_sum_XX\"]\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if bool(placebo) and scalars.get(\"denom_delta_IV_sum_pl_XX\", 0.0) != 0:\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[\"delta_3_1_pl_XX\"] /= scalars[\"denom_delta_IV_sum_pl_XX\"]\n",
    "\n",
    "    # IF agregadas\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for i in (1, 2, 3):\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        IDs_XX[f\"Phi_{i}_XX\"] = 0.0\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if bool(placebo):\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            IDs_XX[f\"Phi_{i}_pl_XX\"] = 0.0\n",
    "\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for p in range(2, max_T_XX + 1):\n",
    "        # Compute and store `non_missing`.\n",
    "        non_missing = int(scalars.get(f\"non_missing_{p}_XX\", 0) == 1)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if aoss_XX == 1 and non_missing == 1 and (f\"Phi_1_{p}_XX\" in IDs_XX.columns) and (f\"S_{p}_XX\" in IDs_XX.columns):\n",
    "            # Compute and store `Phi_p`.\n",
    "            Phi_p = pd.to_numeric(IDs_XX[f\"Phi_1_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `S_p`.\n",
    "            S_p = pd.to_numeric(IDs_XX[f\"S_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `P_p`.\n",
    "            P_p = float(scalars.get(f\"P_{p}_XX\", 0.0))\n",
    "            # Compute and store `delta_p`.\n",
    "            delta_p = float(scalars.get(f\"delta_1_{p}_XX\", np.nan))\n",
    "            # Compute and store `denom`.\n",
    "            denom = float(scalars.get(\"PS_sum_XX\", np.nan))\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if np.isfinite(denom) and denom != 0:\n",
    "                # Compute and store `adj`.\n",
    "                adj = (P_p * Phi_p + (delta_p - float(scalars.get(\"delta_1_1_XX\", np.nan))) * (S_p - P_p)) / denom\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                IDs_XX[\"Phi_1_XX\"] = IDs_XX[\"Phi_1_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if waoss_XX == 1 and non_missing == 1 and (f\"Phi_2_{p}_XX\" in IDs_XX.columns) and (f\"abs_delta_D_{p}_XX\" in IDs_XX.columns):\n",
    "            # Compute and store `Phi_p`.\n",
    "            Phi_p = pd.to_numeric(IDs_XX[f\"Phi_2_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `abs_p`.\n",
    "            abs_p = pd.to_numeric(IDs_XX[f\"abs_delta_D_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `E_abs_p`.\n",
    "            E_abs_p = float(scalars.get(f\"E_abs_delta_D_{p}_XX\", 0.0))\n",
    "            # Compute and store `delta_p`.\n",
    "            delta_p = float(scalars.get(f\"delta_2_{p}_XX\", np.nan))\n",
    "            # Compute and store `denom`.\n",
    "            denom = float(scalars.get(\"E_abs_delta_D_sum_XX\", np.nan))\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if np.isfinite(denom) and denom != 0:\n",
    "                # Compute and store `adj`.\n",
    "                adj = (E_abs_p * Phi_p + (delta_p - float(scalars.get(\"delta_2_1_XX\", np.nan))) * (abs_p - E_abs_p)) / denom\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                IDs_XX[\"Phi_2_XX\"] = IDs_XX[\"Phi_2_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if ivwaoss_XX == 1 and non_missing == 1 and (f\"Phi_3_{p}_XX\" in IDs_XX.columns) and (f\"inner_sum_IV_denom_{p}_XX\" in IDs_XX.columns):\n",
    "            # Compute and store `Phi_p`.\n",
    "            Phi_p = pd.to_numeric(IDs_XX[f\"Phi_3_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `inn_p`.\n",
    "            inn_p = pd.to_numeric(IDs_XX[f\"inner_sum_IV_denom_{p}_XX\"], errors=\"coerce\")\n",
    "            # Compute and store `denom_p`.\n",
    "            denom_p = float(scalars.get(f\"denom_delta_IV_{p}_XX\", 0.0))\n",
    "            # Compute and store `delta_p`.\n",
    "            delta_p = float(scalars.get(f\"delta_3_{p}_XX\", np.nan))\n",
    "            # Compute and store `denom`.\n",
    "            denom = float(scalars.get(\"denom_delta_IV_sum_XX\", np.nan))\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if np.isfinite(denom) and denom != 0:\n",
    "                # Compute and store `adj`.\n",
    "                adj = (denom_p * Phi_p + (delta_p - float(scalars.get(\"delta_3_1_XX\", np.nan))) * (inn_p - denom_p)) / denom\n",
    "                # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                IDs_XX[\"Phi_3_XX\"] = IDs_XX[\"Phi_3_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if bool(placebo):\n",
    "        # Start a loop that iterates over the specified sequence.\n",
    "        for p in range(3, max_T_XX + 1):\n",
    "            # Compute and store `non_missing`.\n",
    "            non_missing = int(scalars.get(f\"non_missing_{p}_pl_XX\", 0) == 1)\n",
    "\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if aoss_XX == 1 and non_missing == 1 and (f\"Phi_1_{p}_pl_XX\" in IDs_XX.columns) and (f\"S_{p}_pl_XX\" in IDs_XX.columns):\n",
    "                # Compute and store `Phi_p`.\n",
    "                Phi_p = pd.to_numeric(IDs_XX[f\"Phi_1_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `S_p`.\n",
    "                S_p = pd.to_numeric(IDs_XX[f\"S_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `P_p`.\n",
    "                P_p = float(scalars.get(f\"P_{p}_pl_XX\", 0.0))\n",
    "                # Compute and store `delta_p`.\n",
    "                delta_p = float(scalars.get(f\"delta_1_{p}_pl_XX\", np.nan))\n",
    "                # Compute and store `denom`.\n",
    "                denom = float(scalars.get(\"PS_sum_pl_XX\", np.nan))\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if np.isfinite(denom) and denom != 0:\n",
    "                    # Compute and store `adj`.\n",
    "                    adj = (P_p * Phi_p + (delta_p - float(scalars.get(\"delta_1_1_pl_XX\", np.nan))) * (S_p - P_p)) / denom\n",
    "                    # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                    IDs_XX[\"Phi_1_pl_XX\"] = IDs_XX[\"Phi_1_pl_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if waoss_XX == 1 and non_missing == 1 and (f\"Phi_2_{p}_pl_XX\" in IDs_XX.columns) and (f\"abs_delta_D_{p}_pl_XX\" in IDs_XX.columns):\n",
    "                # Compute and store `Phi_p`.\n",
    "                Phi_p = pd.to_numeric(IDs_XX[f\"Phi_2_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `abs_p`.\n",
    "                abs_p = pd.to_numeric(IDs_XX[f\"abs_delta_D_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `E_abs_p`.\n",
    "                E_abs_p = float(scalars.get(f\"E_abs_delta_D_{p}_pl_XX\", 0.0))\n",
    "                # Compute and store `delta_p`.\n",
    "                delta_p = float(scalars.get(f\"delta_2_{p}_pl_XX\", np.nan))\n",
    "                # Compute and store `denom`.\n",
    "                denom = float(scalars.get(\"E_abs_delta_D_sum_pl_XX\", np.nan))\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if np.isfinite(denom) and denom != 0:\n",
    "                    # Compute and store `adj`.\n",
    "                    adj = (E_abs_p * Phi_p + (delta_p - float(scalars.get(\"delta_2_1_pl_XX\", np.nan))) * (abs_p - E_abs_p)) / denom\n",
    "                    # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                    IDs_XX[\"Phi_2_pl_XX\"] = IDs_XX[\"Phi_2_pl_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if ivwaoss_XX == 1 and non_missing == 1 and (f\"Phi_3_{p}_pl_XX\" in IDs_XX.columns) and (f\"inner_sum_IV_denom_{p}_pl_XX\" in IDs_XX.columns):\n",
    "                # Compute and store `Phi_p`.\n",
    "                Phi_p = pd.to_numeric(IDs_XX[f\"Phi_3_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `inn_p`.\n",
    "                inn_p = pd.to_numeric(IDs_XX[f\"inner_sum_IV_denom_{p}_pl_XX\"], errors=\"coerce\")\n",
    "                # Compute and store `denom_p`.\n",
    "                denom_p = float(scalars.get(f\"denom_delta_IV_{p}_pl_XX\", 0.0))\n",
    "                # Compute and store `delta_p`.\n",
    "                delta_p = float(scalars.get(f\"delta_3_{p}_pl_XX\", np.nan))\n",
    "                # Compute and store `denom`.\n",
    "                denom = float(scalars.get(\"denom_delta_IV_sum_pl_XX\", np.nan))\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if np.isfinite(denom) and denom != 0:\n",
    "                    # Compute and store `adj`.\n",
    "                    adj = (denom_p * Phi_p + (delta_p - float(scalars.get(\"delta_3_1_pl_XX\", np.nan))) * (inn_p - denom_p)) / denom\n",
    "                    # Execute this call (a helper/utility step needed for the main procedure).\n",
    "                    IDs_XX[\"Phi_3_pl_XX\"] = IDs_XX[\"Phi_3_pl_XX\"] + adj.fillna(0.0)\n",
    "\n",
    "    # SE/CI agregados\n",
    "    # Conditional branch: execute the following block only if the condition is true.\n",
    "    if cluster is not None:\n",
    "        # Compute and store `tmp`.\n",
    "        tmp = IDs_XX[[\"ID_XX\", \"cluster_XX\"]].drop_duplicates()\n",
    "        # Compute and store `N_bar_c_XX`.\n",
    "        N_bar_c_XX = float(tmp.groupby(\"cluster_XX\")[\"ID_XX\"].size().mean())\n",
    "    # Fallback branch executed when none of the previous conditions matched.\n",
    "    else:\n",
    "        # Compute and store `N_bar_c_XX`.\n",
    "        N_bar_c_XX = np.nan\n",
    "\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for j in (1, 2, 3):\n",
    "        # Compute and store `enabled`.\n",
    "        enabled = {1: aoss_XX, 2: waoss_XX, 3: ivwaoss_XX}[j]\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if enabled != 1:\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            continue\n",
    "        # Compute and store `phi_col`.\n",
    "        phi_col = f\"Phi_{j}_XX\"\n",
    "        # Compute and store `se`.\n",
    "        se = _se_from_phi(IDs_XX[phi_col]) if cluster is None else _se_cluster_from_phi(IDs_XX, \"cluster_XX\", phi_col, N_bar_c_XX)\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[f\"sd_delta_{j}_1_XX\"] = se\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[f\"LB_{j}_1_XX\"] = float(scalars.get(f\"delta_{j}_1_XX\", np.nan)) - 1.96 * se\n",
    "        # Execute this statement as part of the main procedure.\n",
    "        scalars[f\"UB_{j}_1_XX\"] = float(scalars.get(f\"delta_{j}_1_XX\", np.nan)) + 1.96 * se\n",
    "\n",
    "        # Conditional branch: execute the following block only if the condition is true.\n",
    "        if bool(placebo):\n",
    "            # Compute and store `phi_col`.\n",
    "            phi_col = f\"Phi_{j}_pl_XX\"\n",
    "            # Compute and store `se`.\n",
    "            se = _se_from_phi(IDs_XX[phi_col]) if cluster is None else _se_cluster_from_phi(IDs_XX, \"cluster_XX\", phi_col, N_bar_c_XX)\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[f\"sd_delta_{j}_1_pl_XX\"] = se\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[f\"LB_{j}_1_pl_XX\"] = float(scalars.get(f\"delta_{j}_1_pl_XX\", np.nan)) - 1.96 * se\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            scalars[f\"UB_{j}_1_pl_XX\"] = float(scalars.get(f\"delta_{j}_1_pl_XX\", np.nan)) + 1.96 * se\n",
    "\n",
    "    # tabla output\n",
    "    # Compute and store `estims`.\n",
    "    estims = [\"aoss\", \"waoss\", \"ivwaoss\"]\n",
    "    # Compute and store `colnames`.\n",
    "    colnames = [\"Estimate\", \"SE\", \"LB CI\", \"UB CI\", \"Switchers\", \"Stayers\"]\n",
    "\n",
    "    # Compute and store `ret`.\n",
    "    ret = np.full((3 * max_T_XX, 6), np.nan, dtype=float)\n",
    "    # Execute this statement as part of the main procedure.\n",
    "    rown: List[str] = []\n",
    "    # Start a loop that iterates over the specified sequence.\n",
    "    for j, est in enumerate(estims, start=1):\n",
    "        # Compute and store `enabled`.\n",
    "        enabled = {\"aoss\": aoss_XX, \"waoss\": waoss_XX, \"ivwaoss\": ivwaoss_XX}[est]\n",
    "        # Start a loop that iterates over the specified sequence.\n",
    "        for p in range(1, max_T_XX + 1):\n",
    "            # Execute this call (a helper/utility step needed for the main procedure).\n",
    "            rown.append(est.upper() if p == 1 else f\"{est}_{p}\")\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if enabled != 1:\n",
    "                # Execute this statement as part of the main procedure.\n",
    "                continue\n",
    "            # Conditional branch: execute the following block only if the condition is true.\n",
    "            if p == 1:\n",
    "                # Compute and store `delta`.\n",
    "                delta = scalars.get(f\"delta_{j}_1_XX\", np.nan)\n",
    "                # Compute and store `se`.\n",
    "                se = scalars.get(f\"sd_delta_{j}_1_XX\", np.nan)\n",
    "                # Compute and store `lb`.\n",
    "                lb = scalars.get(f\"LB_{j}_1_XX\", np.nan)\n",
    "                # Compute and store `ub`.\n",
    "                ub = scalars.get(f\"UB_{j}_1_XX\", np.nan)\n",
    "                # Compute and store `ns`.\n",
    "                ns = scalars.get(f\"N_Switchers_{j}_1_XX\", np.nan)\n",
    "                # Compute and store `nt`.\n",
    "                nt = scalars.get(f\"N_Stayers_{j}_1_XX\", np.nan)\n",
    "            # Fallback branch executed when none of the previous conditions matched.\n",
    "            else:\n",
    "                # Compute and store `delta`.\n",
    "                delta = scalars.get(f\"delta_{j}_{p}_XX\", np.nan)\n",
    "                # Compute and store `ns`.\n",
    "                ns = scalars.get(f\"N_Switchers_{j}_{p}_XX\", np.nan)\n",
    "                # Compute and store `nt`.\n",
    "                nt = scalars.get(f\"N_Stayers_{j}_{p}_XX\", np.nan)\n",
    "                # Compute and store `phi_col`.\n",
    "                phi_col = f\"Phi_{j}_{p}_XX\"\n",
    "                # Conditional branch: execute the following block only if the condition is true.\n",
    "                if cluster is None and phi_col in IDs_XX.columns:\n",
    "                    # Compute and store `se`.\n",
    "                    se = _se_from_phi(IDs_XX[phi_col])\n",
    "                    # Compute and store `lb`.\n",
    "                    lb = delta - 1.96 * se if np.isfinite(se) and np.isfinite(delta) else np.nan\n",
    "                    # Compute and store `ub`.\n",
    "                    ub = delta + 1.96 * se if np.isfinite(se) and np.isfinite(delta) else np.nan\n",
    "                # Fallback branch executed when none of the previous conditions matched.\n",
    "                else:\n",
    "                    # Compute and store `se`.\n",
    "                    se = scalars.get(f\"sd_delta_{j}_{p}_XX\", np.nan)\n",
    "                    # Compute and store `lb`.\n",
    "                    lb = scalars.get(f\"LB_{j}_{p}_XX\", np.nan)\n",
    "                    # Compute and store `ub`.\n",
    "                    ub = scalars.get(f\"UB_{j}_{p}_XX\", np.nan)\n",
    "            # Execute this statement as part of the main procedure.\n",
    "            ret[(j - 1) * max_T_XX + (p - 1), :] = [delta, se, lb, ub, ns, nt]\n",
    "\n",
    "    # Compute and store `out_table`.\n",
    "    out_table = pd.DataFrame(ret, index=rown, columns=colnames)\n",
    "    # ----------------------------\n",
    "    # Pack outputs (R-like object)\n",
    "    # ----------------------------\n",
    "    waoss_method_label_map = {\n",
    "        \"ra\": \"Regression Adjustment\",\n",
    "        \"ps\": \"Propensity Score\",\n",
    "        \"dr\": \"Doubly Robust\",\n",
    "    }\n",
    "    common_support_label = \"No Extrapolation\" if bool(noextrapolation) else \"Extrapolation\"\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"table\": out_table,\n",
    "        \"pairs\": int(max_T_XX),\n",
    "        \"N\": int(df[\"ID_XX\"].nunique()),\n",
    "        \"WAOSS Method\": waoss_method_label_map.get(\n",
    "            str(estimation_method).lower() if estimation_method is not None else None,\n",
    "            str(estimation_method),\n",
    "        ),\n",
    "        \"Polynomial Order\": int(order),\n",
    "        \"Common Support\": common_support_label,\n",
    "    }\n",
    "\n",
    "    if n_clus_XX is not None:\n",
    "        out[\"n_clusters\"] = int(n_clus_XX)\n",
    "\n",
    "    # ----------------------------\n",
    "\n",
    "    # --- Placebo counts for the aggregated (p=1) placebo table ---\n",
    "    # In the pairwise code, counts are stored for each p>=3 as:\n",
    "    #   N_Switchers_{j}_{p}_pl_XX and N_Stayers_{j}_{p}_pl_XX\n",
    "    # But the placebo table (p=1) expects the aggregated totals:\n",
    "    #   N_Switchers_{j}_1_pl_XX and N_Stayers_{j}_1_pl_XX\n",
    "    if placebo:\n",
    "        max_t = int(max_T_XX)\n",
    "        for j in range(1, len(estims) + 1):\n",
    "            sw_sum = 0.0\n",
    "            st_sum = 0.0\n",
    "            for p in range(3, max_t + 1):\n",
    "                nsw = float(scalars.get(f\"N_Switchers_{j}_{p}_pl_XX\", 0.0) or 0.0)\n",
    "                nst = float(scalars.get(f\"N_Stayers_{j}_{p}_pl_XX\", 0.0) or 0.0)\n",
    "    \n",
    "                # Match the R code logic:\n",
    "                # - add switchers only when there are at least 2 stayers in that pairwise placebo\n",
    "                # - add stayers only when there is at least 1 switcher in that pairwise placebo\n",
    "                if nst > 1:\n",
    "                    sw_sum += nsw\n",
    "                if nsw > 0:\n",
    "                    st_sum += nst\n",
    "    \n",
    "            scalars[f\"N_Switchers_{j}_1_pl_XX\"] = sw_sum\n",
    "            scalars[f\"N_Stayers_{j}_1_pl_XX\"] = st_sum\n",
    "\n",
    "\n",
    "\n",
    "    # ----------------------------\n",
    "    # Placebo table (overall p=1)\n",
    "    # ----------------------------\n",
    "    if bool(placebo):\n",
    "        ret_pl = np.full((len(estims), len(colnames)), np.nan, dtype=float)\n",
    "        rown_pl = []\n",
    "        for j, est in enumerate(estims, start=1):\n",
    "            p = 1\n",
    "            rown_pl.append(est.upper())\n",
    "            delta = scalars.get(f\"delta_{j}_{p}_pl_XX\", np.nan)\n",
    "            se = scalars.get(f\"sd_delta_{j}_{p}_pl_XX\", np.nan)\n",
    "            lb = scalars.get(f\"LB_{j}_{p}_pl_XX\", np.nan)\n",
    "            ub = scalars.get(f\"UB_{j}_{p}_pl_XX\", np.nan)\n",
    "            ns = scalars.get(f\"N_Switchers_{j}_{p}_pl_XX\", np.nan)\n",
    "            nt = scalars.get(f\"N_Stayers_{j}_{p}_pl_XX\", np.nan)\n",
    "            ret_pl[j - 1, :] = [delta, se, lb, ub, ns, nt]\n",
    "\n",
    "        out[\"table_placebo\"] = pd.DataFrame(ret_pl, index=rown_pl, columns=colnames)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # -----------------------------------------\n",
    "    # Difference test: AOSS vs WAOSS (overall)\n",
    "    # -----------------------------------------\n",
    "    if bool(aoss_vs_waoss) and (aoss_XX == 1) and (waoss_XX == 1):\n",
    "        # R behavior:\n",
    "        #   diff_delta = delta_aoss - delta_waoss\n",
    "        #   diff_Phi   = Phi_aoss - Phi_waoss   (one row per ID in IDs_XX)\n",
    "        #   sd_diff    = sd(diff_Phi)   [or sd(cluster-summed diff_Phi)]\n",
    "        #   t_stat     = diff_delta * sqrt(n) / sd_diff\n",
    "        #   pval       = 2 * (1 - pnorm(|t_stat|))\n",
    "        #   CI         = diff_delta +/- 1.96 * sd_diff / sqrt(n)\n",
    "        diff = float(scalars.get(\"delta_1_1_XX\", np.nan)) - float(scalars.get(\"delta_2_1_XX\", np.nan))\n",
    "\n",
    "        diff_phi = pd.to_numeric(IDs_XX.get(\"Phi_1_XX\", np.nan), errors=\"coerce\") - pd.to_numeric(\n",
    "            IDs_XX.get(\"Phi_2_XX\", np.nan), errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "        # If clustering, aggregate influence by cluster first (cluster-sum), like the R code.\n",
    "        if cluster is not None and \"cluster_XX\" in IDs_XX.columns:\n",
    "            tmp = pd.DataFrame({\"cluster_XX\": IDs_XX[\"cluster_XX\"], \"diff_phi\": diff_phi})\n",
    "            diff_phi_used = tmp.groupby(\"cluster_XX\", as_index=False)[\"diff_phi\"].sum()[\"diff_phi\"]\n",
    "        else:\n",
    "            diff_phi_used = diff_phi\n",
    "\n",
    "        diff_phi_used = pd.to_numeric(diff_phi_used, errors=\"coerce\").fillna(0.0)\n",
    "        n_eff = int(len(diff_phi_used))\n",
    "\n",
    "        if n_eff <= 1 or not np.isfinite(diff):\n",
    "            sd_diff = np.nan\n",
    "            t_stat = np.nan\n",
    "            pval = np.nan\n",
    "            lb = np.nan\n",
    "            ub = np.nan\n",
    "        else:\n",
    "            sd_diff = float(diff_phi_used.std(ddof=1))\n",
    "            # Guard against sd=0\n",
    "            if (not np.isfinite(sd_diff)) or sd_diff == 0.0:\n",
    "                t_stat = np.nan\n",
    "                pval = np.nan\n",
    "                lb = np.nan\n",
    "                ub = np.nan\n",
    "            else:\n",
    "                t_stat = float(diff * math.sqrt(n_eff) / sd_diff)\n",
    "                # Normal approximation (R uses pnorm)\n",
    "                Phi_abs = 0.5 * (1.0 + math.erf(abs(t_stat) / math.sqrt(2.0)))\n",
    "                pval = float(2.0 * (1.0 - Phi_abs))\n",
    "                se = float(sd_diff / math.sqrt(n_eff))\n",
    "                lb = float(diff - 1.96 * se)\n",
    "                ub = float(diff + 1.96 * se)\n",
    "\n",
    "        out[\"aoss_vs_waoss\"] = pd.DataFrame(\n",
    "            {\n",
    "                \"Estimate\": [diff],\n",
    "                \"SE\": [sd_diff],  # NOTE: R prints SD here (not SE)\n",
    "                \"LB CI\": [lb],\n",
    "                \"UB CI\": [ub],\n",
    "                \"t stat.\": [t_stat],\n",
    "                \"pval.\": [pval],\n",
    "            },\n",
    "            index=[\"Diff.\"],\n",
    "        )\n",
    "\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}