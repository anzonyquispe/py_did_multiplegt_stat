{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the main notebook (which loads pairwise) so this notebook is standalone\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "\n",
    "def _exec_notebook(path: Path) -> None:\n",
    "    # Execute all code cells of a notebook into the current IPython kernel.\n",
    "    nb = nbformat.read(path, as_version=4)\n",
    "    ip = get_ipython()\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"code\" and cell.source.strip():\n",
    "            ip.run_cell(cell.source)\n",
    "\n",
    "def _find_local_notebook(name: str) -> Path:\n",
    "    # Find a notebook in cwd, parents, or /mnt/data (sandbox).\n",
    "    candidates = []\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(4):\n",
    "        candidates.append(p / name)\n",
    "        p = p.parent\n",
    "    candidates.append(Path(\"/mnt/data\") / name)\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"Cannot find %s. Looked in: %s\" % (name, \", \".join(str(c) for c in candidates)))\n",
    "\n",
    "main_nb = _find_local_notebook(\"did_multiplegt_stat_main.ipynb\")\n",
    "if \"did_multiplegt_stat_main\" not in globals():\n",
    "    _exec_notebook(main_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65563c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "from typing import Any, Dict, List, Optional, Sequence, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: checks + plotting\n",
    "# -----------------------------\n",
    "def by_check(df: pd.DataFrame, ID: str, by_var: str) -> bool:\n",
    "    \"\"\"R-equivalent of utils::by_check(): checks that ID is nested within by_var.\"\"\"\n",
    "    tmp = df[[ID, by_var]].dropna()\n",
    "    if tmp.empty:\n",
    "        return True\n",
    "    n_unique = tmp.groupby(ID)[by_var].nunique(dropna=True)\n",
    "    return bool((n_unique <= 1).all())\n",
    "\n",
    "def by_graph(obj: Dict[str, Any]):\n",
    "    \"\"\"Minimal plot: estimates by group (by()).\"\"\"\n",
    "    by_levels = obj.get(\"by_levels\", None)\n",
    "    if not by_levels:\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for j, lev in enumerate(by_levels, start=1):\n",
    "        key = \"results\" if (j == 1 and \"results\" in obj and len(by_levels) == 1) else f\"results_by_{j}\"\n",
    "        res = obj.get(key, None)\n",
    "        if not isinstance(res, dict) or \"table\" not in res:\n",
    "            continue\n",
    "        table = res[\"table\"]\n",
    "        if not isinstance(table, pd.DataFrame) or table.empty:\n",
    "            continue\n",
    "\n",
    "        for rname in table.index.astype(str):\n",
    "            if rname.startswith((\"aoss_\", \"waoss_\", \"ivwaoss_\")) and rname.endswith(\"_1_1_XX\"):\n",
    "                rows.append({\n",
    "                    \"by\": lev,\n",
    "                    \"row\": rname,\n",
    "                    \"Estimate\": float(table.loc[rname, \"Estimate\"]) if \"Estimate\" in table.columns else np.nan,\n",
    "                    \"LB CI\": float(table.loc[rname, \"LB CI\"]) if \"LB CI\" in table.columns else np.nan,\n",
    "                    \"UB CI\": float(table.loc[rname, \"UB CI\"]) if \"UB CI\" in table.columns else np.nan,\n",
    "                })\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    plot_df = pd.DataFrame(rows)\n",
    "    fig, ax = plt.subplots()\n",
    "    for rname, g in plot_df.groupby(\"row\"):\n",
    "        x = np.arange(len(g))\n",
    "        y = g[\"Estimate\"].to_numpy(dtype=float)\n",
    "        yerr = np.vstack([\n",
    "            (g[\"Estimate\"] - g[\"LB CI\"]).to_numpy(dtype=float),\n",
    "            (g[\"UB CI\"] - g[\"Estimate\"]).to_numpy(dtype=float),\n",
    "        ])\n",
    "        ax.errorbar(x, y, yerr=yerr, fmt=\"o\", label=rname)\n",
    "\n",
    "    ax.set_xticks(range(len(by_levels)))\n",
    "    ax.set_xticklabels([str(x) for x in by_levels], rotation=45, ha=\"right\")\n",
    "    ax.set_xlabel(\"by group\")\n",
    "    ax.set_ylabel(\"Estimate\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return {\"figure\": fig, \"data\": plot_df}\n",
    "\n",
    "def by_fd_graph(obj: Dict[str, Any]):\n",
    "    \"\"\"Minimal plot for by_fd(): estimate vs median |ΔD| (or |ΔZ|).\"\"\"\n",
    "    switch_df = obj.get(\"switch_df\", None)\n",
    "    by_levels = obj.get(\"by_levels\", None)\n",
    "    if switch_df is None or by_levels is None:\n",
    "        return None\n",
    "\n",
    "    xvals = None\n",
    "    if isinstance(switch_df, pd.DataFrame) and \"delta_median\" in switch_df.columns:\n",
    "        xvals = switch_df.set_index(\"partition_XX\").reindex(by_levels)[\"delta_median\"].to_numpy(dtype=float)\n",
    "    else:\n",
    "        xvals = np.arange(len(by_levels), dtype=float)\n",
    "\n",
    "    rows = []\n",
    "    for j, lev in enumerate(by_levels, start=1):\n",
    "        key = f\"results_by_{j}\"\n",
    "        res = obj.get(key, None)\n",
    "        if not isinstance(res, dict) or \"table\" not in res:\n",
    "            continue\n",
    "        table = res[\"table\"]\n",
    "        if not isinstance(table, pd.DataFrame) or table.empty:\n",
    "            continue\n",
    "\n",
    "        rname = next((r for r in table.index.astype(str) if r.startswith((\"waoss_\", \"ivwaoss_\", \"aoss_\")) and r.endswith(\"_1_1_XX\")), None)\n",
    "        if rname is None:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"bin\": int(lev),\n",
    "            \"x\": float(xvals[j-1]) if j-1 < len(xvals) else np.nan,\n",
    "            \"Estimate\": float(table.loc[rname, \"Estimate\"]) if \"Estimate\" in table.columns else np.nan,\n",
    "            \"LB CI\": float(table.loc[rname, \"LB CI\"]) if \"LB CI\" in table.columns else np.nan,\n",
    "            \"UB CI\": float(table.loc[rname, \"UB CI\"]) if \"UB CI\" in table.columns else np.nan,\n",
    "            \"row\": rname,\n",
    "        })\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    plot_df = pd.DataFrame(rows).sort_values(\"bin\")\n",
    "    fig, ax = plt.subplots()\n",
    "    y = plot_df[\"Estimate\"].to_numpy(dtype=float)\n",
    "    yerr = np.vstack([\n",
    "        (plot_df[\"Estimate\"] - plot_df[\"LB CI\"]).to_numpy(dtype=float),\n",
    "        (plot_df[\"UB CI\"] - plot_df[\"Estimate\"]).to_numpy(dtype=float),\n",
    "    ])\n",
    "    ax.errorbar(plot_df[\"x\"], y, yerr=yerr, fmt=\"o\")\n",
    "    ax.set_xlabel(\"Median |ΔD| (or |ΔZ|) in bin\")\n",
    "    ax.set_ylabel(\"Estimate\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    return {\"figure\": fig, \"data\": plot_df}\n",
    "\n",
    "# -----------------------------\n",
    "# by_fd quantile partitioning\n",
    "# -----------------------------\n",
    "def _balance_panel_fill(df: pd.DataFrame, id_col: str, t_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Replicates plm::make.pbalanced(..., balance.type='fill') + remap T to 1..T.\"\"\"\n",
    "    df = df.copy()\n",
    "    times = pd.Series(df[t_col].dropna().unique()).sort_values().to_list()\n",
    "    ids = pd.Series(df[id_col].dropna().unique()).to_list()\n",
    "\n",
    "    idx = pd.MultiIndex.from_product([ids, times], names=[id_col, t_col])\n",
    "    df0 = df.set_index([id_col, t_col])\n",
    "    df_bal = df0.reindex(idx).reset_index()\n",
    "\n",
    "    # tsfilled_XX via merge indicator\n",
    "    orig = df[[id_col, t_col]].copy()\n",
    "    orig[\"_orig_row_XX\"] = 1\n",
    "    df_bal = df_bal.merge(orig, on=[id_col, t_col], how=\"left\")\n",
    "    df_bal[\"tsfilled_XX\"] = df_bal[\"_orig_row_XX\"].isna().astype(int)\n",
    "    df_bal = df_bal.drop(columns=[\"_orig_row_XX\"])\n",
    "\n",
    "    # Remap time to 1..T\n",
    "    t_map = {t: i + 1 for i, t in enumerate(times)}\n",
    "    df_bal[t_col] = df_bal[t_col].map(t_map).astype(int)\n",
    "    return df_bal\n",
    "\n",
    "def did_multiplegt_stat_quantiles(\n",
    "    df: pd.DataFrame,\n",
    "    ID: str,\n",
    "    Time: str,\n",
    "    D: str,\n",
    "    Z: Optional[str] = None,\n",
    "    by_opt: int = 2,\n",
    "    quantiles: Optional[Sequence[float]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    High-fidelity translation of the R helper that constructs partition_XX for by_fd.\n",
    "\n",
    "    Key behaviors matched to did_multiplegt_stat_quantiles.R:\n",
    "    - Build the distribution of |ΔD| (or |ΔZ|) among switchers in periods eligible for aggregation.\n",
    "    - Default bin assignment is the last bin (by_opt), so values with CDF == 1 stay in the last bin.\n",
    "    - Return `quantiles` overwritten by the realized CDF cutpoints (quantiles_temp).\n",
    "    \"\"\"\n",
    "    if quantiles is None:\n",
    "        quantiles = np.linspace(0, 1, by_opt + 1).tolist()\n",
    "\n",
    "    df_bal = _balance_panel_fill(df, ID, Time)\n",
    "    diff_var = Z if Z is not None else D\n",
    "\n",
    "    # Ensure diff_var is numeric enough for diff()\n",
    "    if diff_var in df_bal.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df_bal[diff_var]):\n",
    "            try:\n",
    "                df_bal[diff_var] = pd.to_numeric(df_bal[diff_var])\n",
    "            except Exception as e:\n",
    "                raise TypeError(f\"{diff_var} must be numeric to compute first differences.\") from e\n",
    "\n",
    "    df_bal = df_bal.sort_values([ID, Time])\n",
    "    df_bal[\"delta_pre_XX\"] = df_bal.groupby(ID)[diff_var].diff().abs()\n",
    "\n",
    "    # period-level counts (eligible periods require >=1 switcher and >=2 stayers)\n",
    "    df_bal[\"switchers_dummy_XX_num\"] = ((df_bal[\"delta_pre_XX\"].notna()) & (df_bal[\"delta_pre_XX\"] != 0)).astype(int)\n",
    "    df_bal[\"stayers_dummy_XX_num\"] = ((df_bal[\"delta_pre_XX\"].notna()) & (df_bal[\"delta_pre_XX\"] == 0)).astype(int)\n",
    "    df_bal[\"switchers_N_XX\"] = df_bal.groupby(Time)[\"switchers_dummy_XX_num\"].transform(\"sum\")\n",
    "    df_bal[\"stayers_N_XX\"] = df_bal.groupby(Time)[\"stayers_dummy_XX_num\"].transform(\"sum\")\n",
    "    df_bal[\"in_aggregation_XX\"] = ((df_bal[\"switchers_N_XX\"] > 0) & (df_bal[\"stayers_N_XX\"] > 1)).astype(int)\n",
    "\n",
    "    # Switcher rows used to build the distribution\n",
    "    df_switch0 = df_bal[(df_bal[\"delta_pre_XX\"].notna()) & (df_bal[\"delta_pre_XX\"] != 0) & (df_bal[\"in_aggregation_XX\"] == 1)].copy()\n",
    "\n",
    "    if df_switch0.empty:\n",
    "        df_bal[\"partition_XX\"] = np.nan\n",
    "        return {\n",
    "            \"df\": df_bal,\n",
    "            \"val_quantiles\": list(quantiles),\n",
    "            \"quantiles\": list(quantiles),\n",
    "            \"switch_df\": pd.DataFrame(columns=[\"partition_XX\", \"N_switchers\", \"delta_median\"]),\n",
    "            \"quantiles_plot\": None,\n",
    "            \"cut_off\": [],\n",
    "        }\n",
    "\n",
    "    # Frequency distribution over unique |Δ|\n",
    "    dist = (\n",
    "        df_switch0.groupby(\"delta_pre_XX\", as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"freq\"})\n",
    "        .sort_values(\"delta_pre_XX\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    dist[\"cdf\"] = dist[\"freq\"].cumsum() / dist[\"freq\"].sum()\n",
    "\n",
    "    # IMPORTANT (matches R): default is last bin, so CDF==1 stays in last bin\n",
    "    dist[\"partition_XX\"] = int(by_opt)\n",
    "\n",
    "    cut_off: List[float] = []\n",
    "    quantiles_temp: List[float] = [0.0]\n",
    "\n",
    "    for j in range(2, len(quantiles) + 1):  # j = 2..len(quantiles)\n",
    "        lo = float(quantiles[j - 2])\n",
    "        hi = float(quantiles[j - 1])\n",
    "        mask = (dist[\"cdf\"] >= lo) & (dist[\"cdf\"] < hi)\n",
    "        dist.loc[mask, \"partition_XX\"] = j - 1\n",
    "        if (dist[\"partition_XX\"] == (j - 1)).any():\n",
    "            cut_off.append(float(dist.loc[dist[\"partition_XX\"] == (j - 1), \"delta_pre_XX\"].min()))\n",
    "            quantiles_temp.append(float(dist.loc[dist[\"partition_XX\"] == (j - 1), \"cdf\"].max()))\n",
    "\n",
    "    # last cutoff is max |Δ|\n",
    "    cut_off.append(float(dist[\"delta_pre_XX\"].max()))\n",
    "\n",
    "    # Map |Δ| -> partition (exactly as in R, but in pandas)\n",
    "    map_part = dist.set_index(\"delta_pre_XX\")[\"partition_XX\"]\n",
    "\n",
    "    df_bal[\"switchers_XX\"] = ((df_bal[\"delta_pre_XX\"].notna()) & (df_bal[\"delta_pre_XX\"] != 0) & (df_bal[\"in_aggregation_XX\"] == 1)).astype(int)\n",
    "    df_bal[\"partition_XX\"] = 0.0\n",
    "    m_sw = df_bal[\"switchers_XX\"] == 1\n",
    "    df_bal.loc[m_sw, \"partition_XX\"] = df_bal.loc[m_sw, \"delta_pre_XX\"].map(map_part).astype(float)\n",
    "\n",
    "    # Not in aggregation => NA partition (matches R behavior via subset(... != 0))\n",
    "    df_bal.loc[df_bal[\"in_aggregation_XX\"] == 0, \"partition_XX\"] = np.nan\n",
    "\n",
    "    # Summary by partition for plotting\n",
    "    df_sw = df_bal[m_sw].copy()\n",
    "    # some bins may be collapsed; keep only finite partitions\n",
    "    df_sw = df_sw[df_sw[\"partition_XX\"].notna()]\n",
    "    if not df_sw.empty:\n",
    "        df_sw[\"partition_XX\"] = df_sw[\"partition_XX\"].astype(int)\n",
    "        switch_df = (\n",
    "            df_sw.groupby(\"partition_XX\", as_index=False)\n",
    "            .agg(N_switchers=(\"delta_pre_XX\", \"size\"), delta_median=(\"delta_pre_XX\", \"median\"))\n",
    "            .sort_values(\"partition_XX\")\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        switch_df = pd.DataFrame(columns=[\"partition_XX\", \"N_switchers\", \"delta_median\"])\n",
    "\n",
    "    # Quick histogram plot of |Δ| among switchers (optional)\n",
    "    fig = None\n",
    "    try:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(df_switch0[\"delta_pre_XX\"].to_numpy(dtype=float), bins=min(30, max(5, len(dist))))\n",
    "        ax.set_xlabel(\"|Δ|\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(\"|Δ| distribution among switchers (eligible periods)\")\n",
    "        ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "    except Exception:\n",
    "        fig = None\n",
    "\n",
    "    return {\n",
    "        \"df\": df_bal,\n",
    "        \"val_quantiles\": quantiles_temp,\n",
    "        \"quantiles\": quantiles_temp,   # matches R overwrite\n",
    "        \"switch_df\": switch_df,\n",
    "        \"quantiles_plot\": {\"figure\": fig} if fig is not None else None,\n",
    "        \"cut_off\": cut_off,\n",
    "    }\n",
    "\n",
    "def did_multiplegt_stat(\n",
    "    df: pd.DataFrame,\n",
    "    Y: str,\n",
    "    ID: str,\n",
    "    Time: str,\n",
    "    D: str,\n",
    "    Z: Optional[str] = None,\n",
    "    estimator: Optional[Union[str, Sequence[str]]] = None,\n",
    "    estimation_method: Optional[str] = None,\n",
    "    order: int = 1,\n",
    "    noextrapolation: bool = False,\n",
    "    placebo: bool = False,\n",
    "    switchers: Optional[str] = None,\n",
    "    disaggregate: bool = False,\n",
    "    aoss_vs_waoss: bool = False,\n",
    "    exact_match: bool = False,\n",
    "    by: Optional[Sequence[str]] = None,\n",
    "    by_fd: Optional[int] = None,\n",
    "    other_treatments: Optional[Sequence[str]] = None,\n",
    "    cluster: Optional[str] = None,\n",
    "    weight: Optional[str] = None,\n",
    "    legacy_r_phi_scale: str = \"auto\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Python interface mirroring did_multiplegt_stat.R.\"\"\"\n",
    "    if not isinstance(order, int):\n",
    "        raise TypeError(\"order must be an integer.\")\n",
    "    if switchers is not None and switchers not in (\"up\", \"down\"):\n",
    "        raise ValueError(\"Switchers could be either None, 'up' or 'down'.\")\n",
    "\n",
    "    # Default estimator (match R)\n",
    "    if estimator is None and Z is None:\n",
    "        estimator_list = [\"aoss\", \"waoss\"]\n",
    "    elif estimator is None and Z is not None:\n",
    "        estimator_list = [\"ivwaoss\"]\n",
    "    elif isinstance(estimator, str):\n",
    "        estimator_list = [estimator]\n",
    "    else:\n",
    "        estimator_list = list(estimator)\n",
    "\n",
    "    allowed = {\"aoss\", \"waoss\", \"ivwaoss\"}\n",
    "    if len([e for e in estimator_list if e in allowed]) != len(estimator_list):\n",
    "        raise ValueError(\"Syntax error in estimator option: only aoss, waoss and ivwaoss allowed.\")\n",
    "    # --- Stata .ado behavior (Aug 2025): estimation_method is overridden ---\n",
    "    if bool(exact_match):\n",
    "        # Stata: exact_match => forces RA and ignores order/noextrapolation\n",
    "        if estimation_method not in (None, \"ra\", \"dr\", \"ps\"):\n",
    "            raise ValueError(\"Syntax error in estimation_method option.\")\n",
    "        if estimation_method not in (None, \"ra\"):\n",
    "            print(\"As exact_match is specified, estimation_method() is ignored and set to 'ra'.\")\n",
    "        estimation_method = \"ra\"\n",
    "\n",
    "        if bool(noextrapolation):\n",
    "            print(\"As exact_match is specified, noextrapolation is ignored.\")\n",
    "            noextrapolation = False\n",
    "\n",
    "        if order != 1:\n",
    "            print(\"As exact_match is specified, order() is ignored and set to 1.\")\n",
    "            order = 1\n",
    "    else:\n",
    "        # Stata: without exact_match => forces DR for all estimators (ignores user input)\n",
    "        if estimation_method is not None and str(estimation_method).lower() != \"dr\":\n",
    "            print(\"Without exact_match, estimation_method() is ignored (Stata behavior). Using 'dr'.\")\n",
    "        estimation_method = \"dr\"\n",
    "    # ---------------------------------------------------------------\n",
    "    if estimation_method not in (\"ra\", \"dr\", \"ps\"):\n",
    "        raise ValueError(\"Syntax error in estimation_method option.\")\n",
    "    # Stata behavior: even if overall method is DR, AOSS itself is computed via RA.\n",
    "    # Therefore we do not error out when estimation_method is \"dr\" with aoss.\n",
    "    if (\"aoss\" in estimator_list) and (estimation_method == \"ps\"):\n",
    "        raise ValueError(\"The propensity score-based approach is only available for waoss and ivwaoss (not aoss).\")\n",
    "\n",
    "    if (\"ivwaoss\" in estimator_list) and any(e in (\"aoss\", \"waoss\") for e in estimator_list):\n",
    "        raise ValueError(\"The estimation of AOSS or WAOSS cannot be combined with IV-WAOSS.\")\n",
    "    if bool(aoss_vs_waoss) and sum(e in (\"aoss\", \"waoss\") for e in estimator_list) != 2:\n",
    "        raise ValueError(\"To test equality between AOSS and WAOSS you must specify both aoss and waoss.\")\n",
    "    if (\"ivwaoss\" in estimator_list) and (Z is None):\n",
    "        raise ValueError(\"To compute ivwaoss you must specify the IV variable Z.\")\n",
    "\n",
    "    if by is not None and by_fd is not None:\n",
    "        raise ValueError(\"You cannot specify both by and by_fd.\")\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"args\": {\n",
    "            \"Y\": Y,\n",
    "            \"ID\": ID,\n",
    "            \"Time\": Time,\n",
    "            \"D\": D,\n",
    "            \"Z\": Z,\n",
    "            \"estimator\": estimator_list,\n",
    "            \"estimation_method\": estimation_method,\n",
    "            \"order\": int(order),\n",
    "            \"noextrapolation\": bool(noextrapolation),\n",
    "            \"placebo\": bool(placebo),\n",
    "            \"switchers\": switchers,\n",
    "            \"disaggregate\": bool(disaggregate),\n",
    "            \"aoss_vs_waoss\": bool(aoss_vs_waoss),\n",
    "            \"exact_match\": bool(exact_match),\n",
    "            \"by\": list(by) if by is not None else None,\n",
    "            \"by_fd\": int(by_fd) if by_fd is not None else None,\n",
    "            \"other_treatments\": list(other_treatments) if other_treatments is not None else None,\n",
    "            \"cluster\": cluster,\n",
    "            \"weight\": weight,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    df_work = df.copy()\n",
    "    mode = \"_no_by\"\n",
    "    by_levels = [\"_no_by\"]\n",
    "    by_str = None\n",
    "\n",
    "    if by is not None:\n",
    "        by = list(by)\n",
    "        for v in by:\n",
    "            if not by_check(df_work, ID, v):\n",
    "                raise ValueError(\"The by option requires that the variable(s) are constant within ID.\")\n",
    "        comp = df_work[by].copy()\n",
    "        na_row = comp.isna().any(axis=1)\n",
    "        comp = comp.astype(str)\n",
    "        by_total = comp[by[0]].astype(object)\n",
    "        for v in by[1:]:\n",
    "            by_total = by_total.astype(str) + \",\" + comp[v].astype(str)\n",
    "        by_total = by_total.where(~na_row, np.nan)\n",
    "        df_work[\"by_total\"] = by_total\n",
    "        by_levels = pd.Series(df_work[\"by_total\"].dropna().unique()).sort_values().tolist()\n",
    "        by_str = \",\".join(by)\n",
    "        out[\"by_levels\"] = by_levels\n",
    "        mode = \"by\"\n",
    "\n",
    "    if by_fd is not None:\n",
    "        if not isinstance(by_fd, int):\n",
    "            raise TypeError(\"by_fd must be an integer.\")\n",
    "        if 100 % by_fd != 0:\n",
    "            raise ValueError(\"Syntax error in by option. When by_fd is specified it must divide 100.\")\n",
    "        q_levels = [0.0]\n",
    "        for _ in range(by_fd):\n",
    "            q_levels.append(q_levels[-1] + 1.0 / by_fd)\n",
    "\n",
    "        by_set = did_multiplegt_stat_quantiles(df=df_work, ID=ID, Time=Time, D=D, Z=Z, by_opt=by_fd, quantiles=q_levels)\n",
    "        df_work = by_set[\"df\"]\n",
    "        out[\"val_quantiles\"] = by_set.get(\"val_quantiles\")\n",
    "        out[\"quantiles\"] = by_set.get(\"quantiles\")\n",
    "        out[\"switch_df\"] = by_set.get(\"switch_df\")\n",
    "        out[\"quantiles_plot\"] = by_set.get(\"quantiles_plot\")\n",
    "\n",
    "        part = df_work.loc[df_work[\"partition_XX\"].notna() & (df_work[\"partition_XX\"] != 0), \"partition_XX\"]\n",
    "        by_levels = sorted(part.astype(int).unique().tolist())\n",
    "        out[\"by_levels\"] = by_levels\n",
    "        # Match R: warn if point mass collapses bins\n",
    "        if len(by_levels) != by_fd:\n",
    "            print(f\"Point mass > {100/by_fd:.0f}% detected. {by_fd - len(by_levels)} bin(s) collapsed.\")\n",
    "        mode = \"by_fd\"\n",
    "\n",
    "    def _call_main(df_in: pd.DataFrame, by_fd_opt: Optional[Any]) -> Dict[str, Any]:\n",
    "        return did_multiplegt_stat_main(\n",
    "            df=df_in,\n",
    "            Y=Y,\n",
    "            ID=ID,\n",
    "            Time=Time,\n",
    "            D=D,\n",
    "            Z=Z,\n",
    "            estimator=estimator_list,\n",
    "            estimation_method=estimation_method,\n",
    "            order=int(order),\n",
    "            noextrapolation=bool(noextrapolation),\n",
    "            placebo=bool(placebo),\n",
    "            switchers=switchers,\n",
    "            disaggregate=bool(disaggregate),\n",
    "            aoss_vs_waoss=bool(aoss_vs_waoss),\n",
    "            exact_match=bool(exact_match),\n",
    "            weight=weight,\n",
    "            cluster=cluster,\n",
    "            by_fd_opt=by_fd_opt,\n",
    "            other_treatments=list(other_treatments) if other_treatments is not None else None,\n",
    "            legacy_r_phi_scale=legacy_r_phi_scale,\n",
    "        )\n",
    "\n",
    "    if mode == \"_no_by\":\n",
    "        out[\"results\"] = _call_main(df_work, by_fd_opt=None)\n",
    "    elif mode == \"by\":\n",
    "        for j, lev in enumerate(by_levels, start=1):\n",
    "            df_sub = df_work[df_work[\"by_total\"] == lev].copy()\n",
    "            print(f\"Running did_multiplegt_stat with {by_str} = {lev}\")\n",
    "            out[f\"results_by_{j}\"] = _call_main(df_sub, by_fd_opt=None)\n",
    "    else:  # by_fd\n",
    "        diff_var = \"Z\" if \"ivwaoss\" in estimator_list else \"D\"\n",
    "        qs = out.get(\"quantiles\", None)\n",
    "        for j, lev in enumerate(by_levels, start=1):\n",
    "            if isinstance(qs, (list, tuple)) and len(qs) >= j + 1:\n",
    "                left = float(qs[j-1]) * 100\n",
    "                right = float(qs[j]) * 100\n",
    "            else:\n",
    "                left = np.nan\n",
    "                right = np.nan\n",
    "            sep = \"[\" if j == 1 else \"(\"\n",
    "            print(f\"Running did_multiplegt_stat with switchers with abs(delta_{diff_var}) in {sep}{left:.0f}%, {right:.0f}%] quantile bin\")\n",
    "            out[f\"results_by_{j}\"] = _call_main(df_work, by_fd_opt=int(lev))\n",
    "\n",
    "    # Optional graphs\n",
    "    if out[\"args\"].get(\"by\") is not None:\n",
    "        out[\"by_graph\"] = by_graph(out)\n",
    "    if out.get(\"quantiles\") is not None:\n",
    "        out[\"by_fd_graph\"] = by_fd_graph(out)\n",
    "\n",
    "    out[\"_class\"] = \"did_multiplegt_stat\"\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}