{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797dbe40",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "def _expit(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Numerically stable logistic function.\"\"\"\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    out = np.empty_like(x, dtype=float)\n",
        "    pos = x >= 0\n",
        "    out[pos] = 1.0 / (1.0 + np.exp(-x[pos]))\n",
        "    ex = np.exp(x[~pos])\n",
        "    out[~pos] = ex / (1.0 + ex)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _is_glm_binomial(fitted_model) -> bool:\n",
        "    \"\"\"\n",
        "    Best-effort detection of a statsmodels GLM Binomial(logit) result.\n",
        "    Used to decide whether trimming rules should be applied.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        fam = getattr(getattr(fitted_model, \"model\", None), \"family\", None)\n",
        "        if fam is None:\n",
        "            fam = getattr(fitted_model, \"family\", None)\n",
        "        if fam is None:\n",
        "            return False\n",
        "        return fam.__class__.__name__.lower() == \"binomial\"\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def var_extract(term: str, vars_: list[str]) -> dict:\n",
        "    \"\"\"\n",
        "    Python analogue of the R helper `var_extract()` used in lpredict.R.\n",
        "\n",
        "    It parses a coefficient name that encodes values as digits and returns:\n",
        "      - var: list of variable names\n",
        "      - val: list of numeric values (as floats)\n",
        "\n",
        "    This is only used when `factor=True` and the coefficient name contains \"FACT\".\n",
        "    \"\"\"\n",
        "    if len(vars_) > 25:\n",
        "        raise ValueError(\"Interaction limit (25) exceeded. Reduce number of other treatments.\")\n",
        "\n",
        "    s = str(term)\n",
        "    repl = [f\"{chr(65+i)}_XX\" for i in range(len(vars_))]  # A_XX, B_XX, ...\n",
        "    for v, r in zip(vars_, repl):\n",
        "        s = s.replace(v, r)\n",
        "\n",
        "    nums = [float(x) for x in re.findall(r\"\\d+\", s)]\n",
        "    nond = \"\".join(re.findall(r\"\\D+\", s))  # keep only non-digits, concat\n",
        "\n",
        "    for v, r in zip(vars_, repl):\n",
        "        nond = nond.replace(r, v)\n",
        "\n",
        "    vars_out = [x for x in nond.split(\":\") if x != \"\"]\n",
        "    return {\"var\": vars_out, \"val\": nums}\n",
        "\n",
        "\n",
        "def _manual_linear_predict(\n",
        "    df: pd.DataFrame,\n",
        "    outcol: str,\n",
        "    params: pd.Series,\n",
        "    varlist: list[str],\n",
        "    const: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    R-style linear predictor:\n",
        "      df[outcol] = Î£ beta_v * x_v (+ intercept)\n",
        "\n",
        "    Supports:\n",
        "      - plain terms that are columns in df\n",
        "      - interactions \"a:b:c\" (product of columns)\n",
        "      - limited \"I(expr)\" where expr can reference df columns and use + - * / ** ()\n",
        "    \"\"\"\n",
        "    df[outcol] = 0.0\n",
        "\n",
        "    for term in varlist:\n",
        "        if term not in params.index:\n",
        "            continue\n",
        "\n",
        "        coef = params[term]\n",
        "        if pd.isna(coef):\n",
        "            continue\n",
        "        coef = float(coef)\n",
        "\n",
        "        # FACT terms (handled elsewhere in lpredict)\n",
        "        if \"FACT\" in str(term):\n",
        "            continue\n",
        "\n",
        "        # Interaction a:b:c\n",
        "        if \":\" in str(term):\n",
        "            parts = str(term).split(\":\")\n",
        "            ok = all(p in df.columns for p in parts)\n",
        "            if ok:\n",
        "                prod = np.ones(len(df), dtype=float)\n",
        "                for p in parts:\n",
        "                    prod *= pd.to_numeric(df[p], errors=\"coerce\").to_numpy(dtype=float)\n",
        "                df[outcol] = df[outcol].to_numpy(dtype=float) + prod * coef\n",
        "            continue\n",
        "\n",
        "        # Plain column\n",
        "        if str(term) in df.columns:\n",
        "            x = pd.to_numeric(df[str(term)], errors=\"coerce\").to_numpy(dtype=float)\n",
        "            df[outcol] = df[outcol].to_numpy(dtype=float) + x * coef\n",
        "            continue\n",
        "\n",
        "        # I(expr) term (patsy-style)\n",
        "        m = re.match(r\"^I\\((.+)\\)$\", str(term))\n",
        "        if m is not None:\n",
        "            expr = m.group(1)\n",
        "            safe_expr = expr\n",
        "            for col in sorted(df.columns, key=len, reverse=True):\n",
        "                if re.search(rf\"\\b{re.escape(col)}\\b\", safe_expr):\n",
        "                    safe_expr = re.sub(\n",
        "                        rf\"\\b{re.escape(col)}\\b\",\n",
        "                        f\"df[{col!r}].astype(float).to_numpy()\",\n",
        "                        safe_expr\n",
        "                    )\n",
        "            try:\n",
        "                val = eval(safe_expr, {\"np\": np, \"df\": df})\n",
        "                df[outcol] = df[outcol].to_numpy(dtype=float) + np.asarray(val, dtype=float) * coef\n",
        "            except Exception:\n",
        "                # Skip silently (closer to \"do not crash\" behavior)\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "        # Unknown term: skip\n",
        "        continue\n",
        "\n",
        "    # Add intercept if present\n",
        "    if const:\n",
        "        for icpt_name in (\"Intercept\", \"const\", \"(Intercept)\"):\n",
        "            if icpt_name in params.index and not pd.isna(params[icpt_name]):\n",
        "                df[outcol] = df[outcol].to_numpy(dtype=float) + float(params[icpt_name])\n",
        "                break\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def lpredict(\n",
        "    df: pd.DataFrame,\n",
        "    outcol: str,\n",
        "    fitted_model,\n",
        "    varlist=None,\n",
        "    const: bool = True,\n",
        "    prob: bool = False,\n",
        "    factor: bool = False,\n",
        "    sensitivity: float = 1e-10,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add predicted values into `df[outcol]`.\n",
        "\n",
        "    This is a faithful Python analogue of the R internal helper `lpredict()`.\n",
        "\n",
        "    Core behaviors to match R:\n",
        "      - Start from a linear predictor built term-by-term (manual mode).\n",
        "      - If `prob=True`, convert linear predictor to probability via logistic transform.\n",
        "      - If prob/PS prediction, apply trimming:\n",
        "            NaN -> 1\n",
        "            p < 1e-10 -> 0\n",
        "      - If `factor=True` and coefficient names contain \"FACT\", treat them as\n",
        "        encoded interaction indicators and add beta when conditions match.\n",
        "\n",
        "    Notes:\n",
        "      - We *prefer* fitted_model.predict(df) when it works (statsmodels),\n",
        "        but we always keep a manual fallback. When `factor=True`, we use\n",
        "        the manual R-style path to be consistent.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ---- Decide varlist / params ----\n",
        "    try:\n",
        "        params = fitted_model.params\n",
        "        if not isinstance(params, pd.Series):\n",
        "            # best-effort\n",
        "            params = pd.Series(params, index=getattr(fitted_model.params, \"index\", None))\n",
        "        if params.index is None:\n",
        "            raise ValueError(\"params have no index; cannot map coefficients to names.\")\n",
        "    except Exception as e:\n",
        "        raise TypeError(\"lpredict: fitted_model must expose `.params` with named coefficients.\") from e\n",
        "\n",
        "    intercept_names = (\"Intercept\", \"const\", \"(Intercept)\")\n",
        "    if varlist is None:\n",
        "        exog_names = list(getattr(getattr(fitted_model, \"model\", None), \"exog_names\", []))\n",
        "        varlist = [v for v in exog_names if v not in intercept_names]\n",
        "\n",
        "    # R behavior when factor=TRUE:\n",
        "    singletons = []\n",
        "    if factor:\n",
        "        singletons = [v for v in (varlist or []) if \":\" not in str(v)]\n",
        "        # override varlist to coefficient names excluding intercept (as in R)\n",
        "        varlist = [v for v in params.index if v not in intercept_names]\n",
        "\n",
        "    # ---- Preferred path: model.predict(df) when possible and factor=False ----\n",
        "    pred = None\n",
        "    if not factor:\n",
        "        try:\n",
        "            pred = fitted_model.predict(df)\n",
        "        except Exception:\n",
        "            pred = None\n",
        "\n",
        "    if pred is not None:\n",
        "        df[outcol] = np.asarray(pred, dtype=float)\n",
        "    else:\n",
        "        # Manual linear predictor\n",
        "        df = _manual_linear_predict(df, outcol, params=params, varlist=list(varlist), const=const)\n",
        "\n",
        "        # Add FACT terms if requested\n",
        "        if factor:\n",
        "            for term in varlist:\n",
        "                if \"FACT\" not in str(term):\n",
        "                    continue\n",
        "                if term not in params.index or pd.isna(params[term]):\n",
        "                    continue\n",
        "                coef = float(params[term])\n",
        "                vs = var_extract(str(term), singletons)\n",
        "                vars_out = vs.get(\"var\", [])\n",
        "                vals_out = vs.get(\"val\", [])\n",
        "                if len(vars_out) == 0 or len(vals_out) == 0:\n",
        "                    continue\n",
        "                k = min(len(vars_out), len(vals_out))\n",
        "                sel = np.ones(len(df), dtype=bool)\n",
        "                for j in range(k):\n",
        "                    v = vars_out[j]\n",
        "                    if v not in df.columns:\n",
        "                        sel &= False\n",
        "                        continue\n",
        "                    x = pd.to_numeric(df[v], errors=\"coerce\").to_numpy(dtype=float)\n",
        "                    sel &= (x == float(vals_out[j]))\n",
        "                df.loc[sel, outcol] = df.loc[sel, outcol].to_numpy(dtype=float) + coef\n",
        "\n",
        "        # If prob requested, convert linear predictor -> probability (R behavior)\n",
        "        if prob:\n",
        "            arr = df[outcol].astype(float).to_numpy()\n",
        "            df[outcol] = _expit(arr)\n",
        "\n",
        "    # ---- Trimming rule (R) for prob/propensity scores ----\n",
        "    looks_like_ps = isinstance(outcol, str) and outcol.startswith(\"PS_\")\n",
        "    if prob or looks_like_ps or _is_glm_binomial(fitted_model):\n",
        "        p = df[outcol].astype(float).to_numpy()\n",
        "        p = np.where(np.isnan(p), 1.0, p)\n",
        "        p = np.where(p < sensitivity, 0.0, p)\n",
        "        df[outcol] = p\n",
        "\n",
        "    return df\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
